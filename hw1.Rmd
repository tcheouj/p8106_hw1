---
title: "hw1"
author: "Johnstone Tcheou"
date: "2025-02-21"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
---

\newpage 

Set a seed to ensure reproducibility of results. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(81061)
```

```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(ISLR)
library(glmnet)
library(caret)
library(tidymodels)
library(corrplot)
library(ggplot2)
library(plotmo)
library(ggrepel)
library(pls)
```

```{r}
training <- read.csv("housing_training.csv")
testing <- read.csv("housing_test.csv")
```

# Question a

We will be using the `caret` metaengine to conduct a 10-fold cross-validation of a lasso regression on the training dataset.
We will also need to configure the predictors as a matrix, the response variable as a vector, and the testing data as a matrix without the response variable. 

```{r}
predictors <- model.matrix(Sale_Price ~ ., training)[, -1] 
response <- training[, "Sale_Price"]
test <- model.matrix(Sale_Price ~ ., testing)[, -1]
```


Before fitting a model, we should also check for correlations between predictors, which may cause problems with lasso regression.   

```{r}
corrplot::corrplot(
  cor(predictors),
  method = "circle",
  type = "full"
)
```

There are some predictors which are correlated with each other, such as `Total_Bsmt_SF` and `First_Flr_SF`,  `Second_Flr_SF` and `Gr_Liv_Area`, `Kitchen_QualTypical` and `Kitchen_QualGood`, `Fireplaces` and `Fireplace_QuNo_FirePlace`. 

For 10-fold cross validation, we need to use `trainControl()` to specify control parameters, i.e. specifying the resampling method we are using and the number of folds - in this case, cross-validation and 10, respectively. The formula results are stored in `ctrl1`.

We then pass this to the `train()` function, along with the desired model statement as a formula (`Sale_Price ~ .`), the training dataset, `alpha = 1` for lasso regression, and a corresponding lambda grid hopefully wide enough to capture the optimal lambda value. 

```{r}
ctrl1 <- trainControl(method = "cv", number = 10)

lasso_caret <- 
  train(
    Sale_Price ~.,
    data = training,
    method = "glmnet",
    tuneGrid = expand.grid(
      alpha = 1,
      lambda = exp(seq(10, -5, length = 100))
    ),
    trControl = ctrl1
  )
```

```{r}
plot(lasso_caret, xTrans = log)

lasso_caret$bestTune

coef(lasso_caret$finalModel, lasso_caret$bestTune$lambda)
```

Based on the CV RMSE, the optimal lambda that minimizes the CV RMSE is `r lasso_caret$bestTune$lambda`, which corresponds to `r log(lasso_caret$bestTune$lambda)` on the graph. 

Excluding the intercept, there are 37 predictors included in this final model. 

```{r}
lasso_caret_pred <- predict(lasso_caret, newdata = testing)

lasso_caret_testerror <- mean((lasso_caret_pred - testing[, "Sale_Price"])^2)
```

The test error for the selected lasso regression model is `r lasso_caret_testerror`.

For `caret`, to get the lambda within the 1 SE rule, a different trainControl object needs to be initialized, with `oneSE` specified for the `selectionFunction` argument. 

```{r}
ctrl2 <- trainControl(method = "cv", number = 10, selectionFunction = "oneSE")

lasso_caret_1se <- 
  train(
    Sale_Price ~.,
    data = training,
    method = "glmnet",
    tuneGrid = expand.grid(
      alpha = 1,
      lambda = exp(seq(10, -5, length = 100))
    ),
    trControl = ctrl2
  )

plot(lasso_caret_1se, xTrans = log)

lasso_caret_1se$bestTune

coef(lasso_caret_1se$finalModel, lasso_caret_1se$bestTune$lambda)
```

This generates a lambda of `r lasso_caret_1se$bestTune$lambda`. In this model, there are 29 predictors included, excluding the intercept. 

# Question b

With elastic net, the `alpha` argument should be supplied a sequence of values from 0 to 1, being in between the extremes of 0 and 1, representing ridge and lasso regression.

```{r}
elastic_caret <-
  train(
    Sale_Price ~.,
    data = training,
    method = "glmnet",
    tuneGrid = expand.grid(
      alpha = seq(0, 1, length = 31),
      lambda = exp(seq(10, -5, length = 100))
    ),
    trControl = ctrl1
  )

elastic_caret$bestTune
```

```{r}
myCol <- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol))

plot(elastic_caret, par.settings = myPar, xTrans = log)
```

```{r}
coef(elastic_caret$finalModel, elastic_caret$bestTune$lambda)
```

The lambda which minimizes the cross validation MSE is `r elastic_caret$bestTune$lambda`. This model has all 39 predictors (excluding the intercept).  

```{r}
elastic_caret_pred <- predict(elastic_caret, newdata = testing)

elastic_caret_testerror <- mean((elastic_caret_pred - testing[, "Sale_Price"])^2)
```

The test error from this optimal elastic net model is `r elastic_caret_testerror`.

Unlike lasso, the 1SE rule is not applicable to elastic net regression. This is because elastic net has two different regularization parameters, alpha (the mixing of the two penalties), and lambda itself. The premise of the 1SE rule then becomes arbitrary when there are more than 1 regularization parameters that the 1SE can refer to. 

```{r}
elastic_caret_1se <-
  train(
    Sale_Price ~.,
    data = training,
    method = "glmnet",
    tuneGrid = expand.grid(
      alpha = seq(0, 1, length = 31),
      lambda = exp(seq(10, -5, length = 100))
    ),
    trControl = ctrl2
  )

elastic_caret_1se$bestTune
```

```{r}
myCol <- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol))

plot(elastic_caret_1se, par.settings = myPar, xTrans = log)

#coef(elastic_caret_1se$finalModel, elastic_caret_1se$bestTune$lambda)

elastic_caret_1se_pred <- predict(elastic_caret, newdata = testing)

elastic_caret_1se_testerror <- mean((elastic_caret_pred - testing[, "Sale_Price"])^2)
```

The test error when the 1SE rule is applied is `r elastic_caret_1se_testerror`. 

# Question c

```{r}
pls_caret <- 
  train(
    predictors, response,
    method = "pls",
    tuneGrid = data.frame(ncomp = 1:19),
    trControl = ctrl1,
    preProcess = c("center", "scale")
  )

pls_caret_pred <- predict(pls_caret, newdata = test)

pls_caret_testerror <- mean((pls_caret_pred - testing[, "Sale_Price"])^2)
```

The test error for the optimal partial least squares model is `r pls_caret_testerror`.  

```{r}
coef(pls_caret$finalModel, pls_caret$bestTune$ncomp)
```

This optimal PLR model also has 39 predictors, excluding the intercept. 

# Question d

The best model to predict the response is the model with the lowest training error - which is lasso regression. Applied to the training data, the lasso model has a mean RMSE of 22709.16, while partial least squares has a mean RMSE of 22909.59, and elastic has a mean RMSE of 23001.77. Therefore, the best model is the lasso regression model. 

```{r}
resamp <- resamples(
  list(lasso = lasso_caret, elastic = elastic_caret, pls = pls_caret)
)

summary(resamp)

bwplot(resamp, metric = "RMSE")
```

# Question e

We will be using `glmnet` to fit a lasso model on the training data. 

Fitting the lasso model with `glmnet` requires `alpha` to be 1 for lasso regression, and passing a sequence of `lambda` values to hopefully capture the optimal lambda. The lambda values must be in descending order, hence the initial sequence value of 10 and the terminal sequence value of -20. 

```{r}
lasso_glmnet <- 
  glmnet(
    predictors,
    response, 
    alpha = 1, 
    lambda = exp(seq(10, -5, length = 100)) 
)

mat.coef <- coef(lasso_glmnet)
dim(mat.coef)

plot_glmnet(lasso_glmnet)
```

Use 10-fold cross validation to determine optimal lambda and regression parameters. 

```{r}
lasso_glmnet_cv <-
  cv.glmnet(
    predictors, 
    response,
    alpha = 1,
    lambda = exp(seq(10, -5, length = 100))
  )

plot(lasso_glmnet_cv)
abline(h = (lasso_glmnet_cv$cvm + lasso_glmnet_cv$cvsd)[which.min(lasso_glmnet_cv$cvm)], col = 4, lwd = 2)

lasso_glmnet_cv$lambda.1se

lasso_glmnet_cv$cvm[which.min(lasso_glmnet_cv$cvm)]
```

The lambda value, our tuning parameter, that minimizes MSE is given by `r lasso_glmnet_cv$lambda.min`, and the smallest lambda value within 1 SE of the MSE is given by `r lasso_glmnet_cv$lambda.1se`. With the lambda that minimizes MSE, the test error is `r lasso_glmnet_cv$cvm[which.min(lasso_glmnet_cv$cvm)]`.

To get the parameters of the model which minimizes MSE, we need to pass the corresponding lambda, `lasso_glmnet_cv$lambda_min`, to the `s` argument of `predict()`. 

```{r}
predict(lasso_glmnet_cv, s = lasso_glmnet_cv$lambda.min, type = "coefficients") 
dim(predict(lasso_glmnet_cv, s = lasso_glmnet_cv$lambda.min, type = "coefficients"))

predict(lasso_glmnet_cv, s = lasso_glmnet_cv$lambda.1se, type = "coefficients") 
dim(predict(lasso_glmnet_cv, s = lasso_glmnet_cv$lambda.1se, type = "coefficients"))
```

Both models, with and without the 1SE rule, have 40 parameters included in the model.

```{r}
predy2_lasso <- predict(lasso_glmnet_cv, s = lasso_glmnet_cv$lambda.min, newx = test, type = "response")

test_error_lasso <- mean((testing$Sale_Price - predy2_lasso)^2) 
```

After fitting the lasso regression model to the testing dataset, the test error is `r test_error_lasso`.
